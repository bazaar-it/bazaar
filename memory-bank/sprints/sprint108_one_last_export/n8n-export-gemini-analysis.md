# n8n Workflow: Export Video Intelligence Loop

## Objective
Wire every successful Remotion export into an automated review loop: once an export is marked `completed`, push the resulting MP4 to Gemini for qualitative analysis and email the insights (with playback link) to the Bazaar ops inbox.

## Key Data Sources
- `public."bazaar-vid_export_analytics"`: event log generated by `ExportTrackingService.trackEvent`. The row with `event = 'completed'` is the most reliable hook (written inside the same tx as `exports` status update).
- `public."bazaar-vid_exports"`: canonical export payload. Columns we need: `render_id`, `output_url`, `format`, `quality`, `duration`, `metadata`, `project_id`, `user_id`, timestamps.
- `public."bazaar-vid_user"`: join on `user_id` â†’ `email`, `name` (optional).

## Trigger Strategy
1. Prefer a DB-driven trigger to avoid additional app changes. n8nâ€™s **Postgres Trigger** node (LISTEN/NOTIFY) is not supported on Neon; instead use a scheduled poll with dedupe:
   ```sql
   SELECT ea.id, ea.export_id, ea.created_at
   FROM public."bazaar-vid_export_analytics" ea
   WHERE ea.event = 'completed' AND ea.created_at > NOW() - INTERVAL '2 days'
   ORDER BY ea.created_at ASC;
   ```
   Persist `ea.id` in n8n static data to skip already processed records.
2. If real-time latency is critical, add a tiny webhook call inside `ExportTrackingService.updateExportStatus` after the `completed` branch; point it at n8nâ€™s Webhook node and reuse the downstream steps.

## Workflow Outline (Polling variant)
1. **Schedule Trigger** â€“ every 5 minutes.
2. **Postgres (Query new completions)** â€“ run the SQL above with `Continue On Fail = false` and `Limit = 50`. Use `{{$json["lastSeenAnalyticsId"]}}` (from static data) in the WHERE clause when available.
3. **IF (Any rows?)** â€“ guard against empty result.
4. **Loop over rows** â€“ n8n Split In Batches (size 1) to process sequentially.
5. **Postgres (Hydrate export)** â€“ parameterized query:
   ```sql
   SELECT e.id,
          e.render_id,
          e.output_url,
          e.format,
          e.quality,
          e.duration,
          e.metadata,
          e.created_at,
          e.completed_at,
          p.slug       AS project_slug,
          u.email      AS user_email,
          coalesce(u.name, 'Bazaar Creator') AS user_name
   FROM public."bazaar-vid_exports" e
   JOIN public."bazaar-vid_project" p ON p.id = e.project_id
   JOIN public."bazaar-vid_user" u     ON u.id = e.user_id
   WHERE e.id = $1;
   ```
6. **HTTP Request (Download export)** â€“ GET `output_url`, `Download` = *Yes*, store in Binary key `video`.
7. **HTTP Request (Gemini File Upload)** â€“ POST multipart to `https://generativelanguage.googleapis.com/v1beta/files?key=<API_KEY>`
   - Part 1 (JSON): `{ "file": { "display_name": "${project_slug}-${render_id}", "mime_type": "video/mp4" } }`
   - Part 2 (Binary): attach binary `video`.
   - Response â†’ `{{$json["name"]}}` (e.g. `files/abc123`). Store as `geminiFileName`.
8. **HTTP Request (Gemini Analysis)** â€“ POST `https://generativelanguage.googleapis.com/v1beta/models/gemini-1.5-flash-latest:generateContent?key=<API_KEY>` with body:
   ```json
   {
     "contents": [
       {
         "parts": [
           { "file_data": { "file_name": "{{$json["geminiFileName"]}}" } },
           { "text": "You are the QA system for Bazaar motion graphics. Review the video and provide: 1) 3-sentence overview, 2) visual quality issues or glitches, 3) motion/tempo feedback, 4) actionable suggestions."
           }
         ]
       }
     ]
   }
   ```
   Capture `{{$json["candidates"][0]["content"]["parts"][0]["text"]}}` as `analysisText`.
9. **Set (Assemble email payload)** â€“ compose subject & HTML combining:
   - Project + render id
   - Export metadata (format, quality, duration, created_at)
   - Gemini analysis text (convert to HTML paragraphs).
   - Direct `output_url` link plus fallback instructions.
10. **Email Send** â€“ use n8n SMTP node or Resend API:
    - To: ops list (e.g. `exports@bazaar.it`), optionally CC project owner `user_email`.
    - Attachments: only if file size < 18MB (check `file_size` column); otherwise include link only.
11. **Postgres (Mark audit)** â€“ insert a lightweight log row or update `metadata` via REST hook (optional) so UI can show â€œanalysis sentâ€. For example call Bazaar internal API `POST /api/exports/{id}/analysis` if/when added.
12. **Set Static Data** â€“ update `lastSeenAnalyticsId` to the latest processed `ea.id`.

## Error & Retry Handling
- Wrap Gemini calls with `Continue On Fail = true` and branch errors into a Slack/email alert that still sends the export link but flags missing analysis.
- If Gemini upload fails because of size, switch to using the public `output_url` directly inside `file_data.file_uri`; Gemini accepts HTTPS URIs when headers allow anonymous GET.
- Rate limits: schedule at â‰¥5 min; Gemini 1.5 flash allows ~360 RPM per project. Respect file upload quota (~20 files/min) by batching.

## Secrets & Environment
- Postgres: provision a dedicated read-only user for n8n (`bazaar_vid_readonly`) limited to the three tables.
- Gemini: store API key in n8n credentials, scope to restricted project.
- Email: prefer Resend API key already used by the platform to keep branding aligned.

## Deployment Checklist
1. âœ… Create n8n credentials (Postgres, Gemini, SMTP/Resend).
2. âœ… Import workflow JSON to staging n8n, run with Neon dev database.
3. âœ… Validate on a dev export; confirm email formatting.
4. ðŸ”„ Switch Postgres credentials to production Neon project.
5. ðŸ”„ Shorten schedule interval if exports > 10/day.
6. ðŸ”’ Document in `/memory-bank/sprints/sprint108_one_last_export/progress.md` after go-live.

## Open Questions
- Do we want to notify the end user automatically or only internal ops? (Currently ops only.)
- Should analysis be persisted back into Bazaar UI for later review?
- Is there a retention policy for Gemini-uploaded files? (Delete via `DELETE /v1beta/{file_name}` after email is sent.)
